<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>操作系统 on </title>
        <link>http://localhost:1313/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/</link>
        <description>Recent content in 操作系统 on </description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en</language>
        <copyright>clp</copyright>
        <lastBuildDate>Sat, 08 Mar 2025 00:48:44 +0800</lastBuildDate><atom:link href="http://localhost:1313/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>操作系统</title>
        <link>http://localhost:1313/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/</link>
        <pubDate>Sat, 08 Mar 2025 00:48:44 +0800</pubDate>
        
        <guid>http://localhost:1313/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/</guid>
        <description>&lt;p&gt;操作系统相当于软件和硬件之间的桥梁，屏蔽了硬件层的复杂性。核心部分是内核，本质上也是一个应用程序。&lt;/p&gt;
&lt;h1 id=&#34;概述&#34;&gt;概述
&lt;/h1&gt;&lt;h2 id=&#34;基本功能&#34;&gt;基本功能
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;进程管理
进程控制、进程同步、进程通信、死锁处理、处理机调度等。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;内存管理
内存分配、地址映射、内存保护与共享、虚拟内存等。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;文件管理
文件存储空间的管理、目录管理、文件读写管理和保护等。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;设备管理
完成用户的 I/O 请求，方便用户使用各种设备，并提高设备的利用率。
主要包括缓冲管理、设备分配、设备处理、虛拟设备等&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;网络管理&lt;/p&gt;
&lt;p&gt;负责管理计算机网络的使用&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;安全管理&lt;/p&gt;
&lt;p&gt;用户的身份认证，访问控制等&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;用户态和内核态&#34;&gt;用户态和内核态
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;用户态(User Mode)&lt;/strong&gt; : 用户态运行的进程可以直接读取用户程序的数据。用户态就是执行在用户空间中。 当需要调用操作系统提供的内核态级别功能时，需要系统调用&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;内核态(Kernel Mode)&lt;/strong&gt;：可以直接读取到计算机的任何资源，不受限制&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;切换方法&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;系统调用：用户主动请求切换到内核态，使用操作系统提供的接口。系统调用按照功能可以分为设备管理，文件管理，进程管理和内存管理。&lt;/li&gt;
&lt;li&gt;中断：当外围设备完成时，发出中断请求，cpu需要暂停去执行中断信号。如果先前执行的指令是用户态下的，那么这个时候就发生了用户态到内核态的切换。&lt;/li&gt;
&lt;li&gt;异常：当CPU执行用户态程序时，发生不可知的异常，就会切换到内核态&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;为什么需要分为两个态&#34;&gt;为什么需要分为两个态
&lt;/h3&gt;&lt;p&gt;有一些指令是比较危险的比如内存分配、设置时钟、IO 处理等，如果所有的程序都能使用这些指令的话，会对系统的正常运行造成灾难性地影响。需要限制这些危险指令只能内核态运行&lt;/p&gt;
&lt;p&gt;如果计算机系统中&lt;strong&gt;只有一个内核态，那么所有程序或进程都必须共享系统资源&lt;/strong&gt;，例如内存、CPU、硬盘等，这将导致系统资源的竞争和冲突，从而影响系统性能和效率。并且，这样也会让系统的安全性降低，毕竟所有程序或进程都具有相同的特权级别和访问权限。&lt;/p&gt;
&lt;h2 id=&#34;系统调用的过程&#34;&gt;系统调用的过程
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;用户态的程序发起系统调用，由于系统调用涉及一些特权指令，用户态程序权限不足，因此会中断执行（叫做Trap）&lt;/li&gt;
&lt;li&gt;发生中断后，当前CPU执行的程序会中断，跳转到中断处理程序。内核程序开始执行，开始处理系统调用&lt;/li&gt;
&lt;li&gt;内核处理完毕后，主动触发Trap，会再次发生中断。切换回用户态工作&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;进程和线程&#34;&gt;进程和线程
&lt;/h1&gt;&lt;p&gt;进程是&lt;strong&gt;程序的一次运行，比如打开微信就是一个进程&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;线程是&lt;strong&gt;进程的一个执行路径，比如微信进行里面有一个线程负责接收最新消息&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;区别&#34;&gt;区别
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;根本区别：进程是操作系统资源分配的基本单位，线程是CPU调度的基本单位。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;内存分配：&lt;strong&gt;同一进程的&lt;/strong&gt;线程共享&lt;/strong&gt;本进程的地址&lt;strong&gt;空间和资源&lt;/strong&gt;，而&lt;strong&gt;进程之间&lt;/strong&gt;的地址空间和资源是相互&lt;strong&gt;独立的&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;系统开销：&lt;strong&gt;由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，所付出的开销远大于&lt;/strong&gt;创建或撤&lt;/strong&gt;销线程时的&lt;strong&gt;开销&lt;/strong&gt;。每个进程都有独立的代码和数据空间（程序上下文），&lt;strong&gt;程序之间的切换会有较大的开销&lt;/strong&gt;；线程可以看做轻量级的进程，同一类线程共享代码和数据空间，每个线程都有自己独立的运行栈和程序计数器（PC），&lt;strong&gt;线程&lt;/strong&gt;之间&lt;strong&gt;切换的开销小&lt;/strong&gt;。线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。&lt;/p&gt;
&lt;p&gt;**通信方面：**线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助 IPC&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;包含关系&lt;/strong&gt;：线程是进程划分成的更小的运行单位，一个进程在其执行的过程中可以产生多个线程。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;影响关系：&lt;strong&gt;一个进程崩溃后，在保护模式下不会对其他进程产生影响，但是&lt;/strong&gt;一个线程崩溃可能导致整个进程都死掉&lt;/strong&gt;。所以多进程要比多线程健壮。&lt;/p&gt;
&lt;h2 id=&#34;为什么有了进程还需要线程&#34;&gt;为什么有了进程还需要线程
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;资源开销方面&lt;/li&gt;
&lt;li&gt;线程更轻量级，一个进程可以创建多个线程&lt;/li&gt;
&lt;li&gt;线程可以并发处理，进程不可以&lt;/li&gt;
&lt;li&gt;进程通信需要借助PIC，同一进程之间的线程通信无需调用内核（因为共享内存和文件）&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;为什么要使用多线程&#34;&gt;为什么要使用多线程
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;线程轻量级，且所需要的系统开销小&lt;/li&gt;
&lt;li&gt;实现高并发&lt;/li&gt;
&lt;li&gt;单核时代，多线程为了提高进程利用cpu和io系统的效率，如果一个进程只有一个线程，一个线程被阻塞整个进程都被阻塞，这样不能同时利用cpu和io系统&lt;/li&gt;
&lt;li&gt;多核时代，多线程为了提高进程利用多核cpu的能力，不同线程利用不同cpu&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;线程间的同步方式多个线程并发执行同步避免资源冲突&#34;&gt;线程间的同步方式（多个线程并发执行，同步避免资源冲突）
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;互斥锁(Mutex)&lt;/strong&gt; ：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。比如 Java 中的 &lt;code&gt;synchronized&lt;/code&gt; 关键词和各种 &lt;code&gt;Lock&lt;/code&gt; 都是这种机制。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;读写锁（Read-Write Lock）&lt;/strong&gt; ：允许&lt;strong&gt;多个线程同时读&lt;/strong&gt;取共享资源，但只有&lt;strong&gt;一个线程&lt;/strong&gt;可以对共享资源进行&lt;strong&gt;写操作&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;信号量(Semaphore)&lt;/strong&gt; ：它允许同一时刻&lt;strong&gt;多个线程访问同一资源&lt;/strong&gt;，但是需要控制同一时刻访问此资源的&lt;strong&gt;最大线程数量&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;屏障（Barrier）&lt;/strong&gt; ：屏障是一种同步原语，用于等待多个线程到达某个点再一起继续执行。当一个线程到达屏障时，它会停止执行并等待其他线程到达屏障，直到所有线程都到达屏障后，它们才会一起继续执行。比如 Java 中的 &lt;code&gt;CyclicBarrier&lt;/code&gt; 是这种机制。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;事件(Event)&lt;/strong&gt; :Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;pcb&#34;&gt;PCB
&lt;/h1&gt;&lt;p&gt;**进程控制块，**是操作系统用来管理和跟踪进程的数据结构，每个进程对应一个独立PCB。&lt;/p&gt;
&lt;p&gt;包含内容：进程的描述信息（进程名字，标识符等），进程的调度信息，包括阻塞原因，进程状态，进程优先级。进程对资源的需求情况（cpu时间，内存空间）。进程打开的文件信息&lt;/p&gt;
&lt;h2 id=&#34;进程的状态&#34;&gt;进程的状态
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;创建状态(new)&lt;/strong&gt;：进程正在被创建。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;就绪状态(ready)&lt;/strong&gt;：进程获得了所需资源，等待&lt;strong&gt;处理器分配的时间片&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;运行状态(running)&lt;/strong&gt;：进程正在&lt;strong&gt;处理器&lt;/strong&gt;上运行。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;阻塞状态(waiting)&lt;/strong&gt;：又称为等待状态，进程正在等&lt;strong&gt;待某资源为可用&lt;/strong&gt;或&lt;strong&gt;IO 操作完成&lt;/strong&gt;。即使处理器空闲，该进程也不能运行。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;结束状态(terminated)&lt;/strong&gt;：&lt;strong&gt;进程正常结束&lt;/strong&gt;或其他原因&lt;strong&gt;中断退出运行&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/img/image.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;进程间的通信方式ipc&#34;&gt;进程间的通信方式IPC
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;管道/匿名管道(Pipes)&lt;/strong&gt; ：用于&lt;strong&gt;父子进程间&lt;/strong&gt;或者&lt;strong&gt;兄弟进程之间&lt;/strong&gt;的通信。管道其实就是&lt;strong&gt;内核中的缓存&lt;/strong&gt;，从一端写入，另一端读取数据。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;有名管道(Names Pipes) :&lt;strong&gt;为了克服管道的缺点（只能在有关系的进程间通信），提出了有名管道。有名管道严格遵循&lt;/strong&gt;先进先出&lt;/strong&gt;(first in first out)。有名管道以&lt;strong&gt;磁盘文件的方式存在&lt;/strong&gt;，可以实现本机任意两个进程通信。管道的特点是&lt;strong&gt;使用简单，缺点是通信方式效率低&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;信号(Signal)&lt;/strong&gt; ：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;消息队列(Message Queuing)&lt;/strong&gt; ：消息队列面向记录，可以独立于读写进程存在。消息队列存放在内核中，只有在内核重启或者显式地删除一个消息队列时，该消息队列才会被真正的删除。消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取.比 FIFO 更有优势。消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺点。消息队列不适合比较大的数据传输，因为每个消息体有最大长度限制。消息队列通信的过程中，存在用户态到内核态之间的数据拷贝开销。因为写入数据的时候会发生用户态到内核态之间的转换。读数据的时候，会发生内核态到用户态转换的过程。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;共享内存(Shared memory)&lt;/strong&gt; ：多个进程访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据的更新。这种方式需要依靠某种同步操作，如&lt;strong&gt;互斥锁&lt;/strong&gt;和&lt;strong&gt;信号量&lt;/strong&gt;等。可以说这是最有用的进程间通信方式。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;信号量(Semaphores)&lt;/strong&gt; ：用了共享内存通信，为了防止多线程进行资源，需要一个保护机制，所以引入了信号量。信号量是一个&lt;strong&gt;计数器，&lt;strong&gt;有两个原子操作即&lt;/strong&gt;p，v操作&lt;/strong&gt; 。P操作信号量减去 -1，相减后如果信号量**&amp;lt;0**，则表明资源已被占用，进程&lt;strong&gt;需阻塞等待&lt;/strong&gt;；相减后如果信号量**&amp;gt;=0**，则表明还有资源可使用，进程可正常&lt;strong&gt;继续执行&lt;/strong&gt;。V操作，信号量加上 1，相加后如果信号量&amp;lt;= 0，则表明当前有阻塞中的进程，于是会将该进程&lt;strong&gt;唤醒运行&lt;/strong&gt;；相加后如果信号量&amp;gt;0，则表明当前没有阻塞中的进程。P 操作是用在&lt;strong&gt;进入共享资源之前&lt;/strong&gt;，V操作是用在离开&lt;strong&gt;共享资源之后&lt;/strong&gt;，这两个操作是必须成对出现的&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;套接字(Sockets)&lt;/strong&gt; : 前面提到方法都是在同一台主机上进行进程间通信，那要想跨网络与不同主机上的进程之间通信，就需要 Socket 通信了。 此方法主要用于在客户端和服务器之间通过网络进行通信。客户端创建一个socket对象，绑定服务器ip和端口。服务器创建一个serberSocket，监听端口。服务端接收请求时就响应请求。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;进程调度算法&#34;&gt;进程调度算法
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;先到先服务(FCFS)调度算法&lt;/strong&gt; : 从就绪队列中选择一个最先进入该队列的进程为之分配资源，优点&lt;strong&gt;简单易实现，缺点是平均等待时间较长。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;短作业优先(SJF)的调度算法&lt;/strong&gt; : 从就绪队列中&lt;strong&gt;选出一个估计运行时间最短的进程为之分配资源&lt;/strong&gt;，&lt;strong&gt;缺点是可能导致长作业饿死，并且需要知道下一个进程的执行时间。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;时间片轮转调度算法&lt;/strong&gt; : ，&lt;strong&gt;将CPU时间划分成一个个的时间片（time slice）&lt;/strong&gt;，为就绪队列中的&lt;strong&gt;进程依次轮流分配一个时间片的CPU&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;时间片轮转算法的效率和时间片的大小有很大关系： 如果&lt;strong&gt;时间片太小&lt;/strong&gt;，会导致进程&lt;strong&gt;切换得太频繁&lt;/strong&gt;，在进程切换上就会花过多时间。而如果&lt;strong&gt;时间片过长&lt;/strong&gt;，那么&lt;strong&gt;实时性就不能得到保证&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;优先级调度&lt;/strong&gt; ： 从就绪队列中选择&lt;strong&gt;优先级最高的进程&lt;/strong&gt;为之分配资源，具有相同优先级的进程以先到先服务的方式执行。&lt;strong&gt;低优先级的进程可能被饿死。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;多级反馈队列调度算法&lt;/strong&gt; ：前面介绍的几种进程调度的算法都有一定的局限性。如短进程优先的调度算法，仅照顾了短进程而忽略了长进程 。多级反馈队列调度算法既能使&lt;strong&gt;高优先级的作业得到响应又能使短作业（进程）迅速完成&lt;/strong&gt;。因而它是目前被公认的一种较好的进程调度算法，UNIX 操作系统采取的便是这种调度算法。具体做法：将就绪队列拆分成若干个，不用的就绪队列采用不同的调度算法。对于优先级低的队列用时间片轮转方法。其他队列遵循先到先服务。&lt;strong&gt;按照队列优先级调度，首先调度最优优先级队列的进程&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&#34;僵尸进程和孤儿进程&#34;&gt;僵尸进程和孤儿进程
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;僵尸进程&lt;/strong&gt;：&lt;strong&gt;子进程已经终止，但是其父进程仍在运行&lt;/strong&gt;，且父进程没有调用 wait()或 waitpid()等系统调用来获取子进程的状态信息，释放子进程占用的资源，导致&lt;strong&gt;子进程的 PCB 依然存在于系统中&lt;/strong&gt;，但无法被进一步使用。这种情况下，子进程被称为“僵尸进程”。避免僵尸进程的产生，父进程需要及时调用 &lt;strong&gt;wait()或 waitpid()系统调用来回收子进程。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;孤儿进程&lt;/strong&gt;：一个进程的&lt;strong&gt;父进程已经终止或者不存在&lt;/strong&gt;，但是该进程仍在运行。这种情况下，该进程就是孤儿进程。为了避免孤儿进程占用系统资源，操作系统会将孤儿进程的父进程设置为 init 进程（进程号为 1），由 &lt;strong&gt;init 进程&lt;/strong&gt;来回收孤儿进程的资源。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;查找僵尸进程&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;top命令 zombie表示僵尸进程的数量&lt;/p&gt;
&lt;h2 id=&#34;死锁&#34;&gt;死锁
&lt;/h2&gt;&lt;p&gt;多个进程/线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。比如两个进程A,B，进程 A 占用资源 X 并且请求资源 Y，而进程 B 已经占用了资源 Y 并请求资源 X。两个进程都在等待对方释放资源，无法继续执行，陷入了死锁状态。&lt;/p&gt;
&lt;h3 id=&#34;死锁的四个必要条件&#34;&gt;死锁的四个必要条件
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;互斥&lt;/strong&gt;：&lt;strong&gt;资源必须处于非共享模式&lt;/strong&gt;，即一次只有一个进程可以使用。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;占有并等待&lt;/strong&gt;：经得到了某个资源的进程可以再请求新的资源。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;非抢占&lt;/strong&gt;：已经分配给一个进程的资源不能强制性地被抢占，它只能被占有它的进程显式地释放。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;循环等待&lt;/strong&gt;：有一组等待进程 &lt;code&gt;{P0, P1,..., Pn}&lt;/code&gt;， &lt;code&gt;P0&lt;/code&gt; 等待的资源被 &lt;code&gt;P1&lt;/code&gt; 占有，&lt;code&gt;P1&lt;/code&gt; 等待的资源被 &lt;code&gt;P2&lt;/code&gt; 占有，……，&lt;code&gt;Pn-1&lt;/code&gt; 等待的资源被 &lt;code&gt;Pn&lt;/code&gt; 占有，&lt;code&gt;Pn&lt;/code&gt; 等待的资源被 &lt;code&gt;P0&lt;/code&gt; 占有。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;同时满足这四个条件不一定发生死锁&lt;/p&gt;
&lt;h3 id=&#34;解决死锁的方法&#34;&gt;解决死锁的方法
&lt;/h3&gt;&lt;h3 id=&#34;1-预防&#34;&gt;&lt;strong&gt;1. 预防&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;是采用某种策略，&lt;strong&gt;限制并发进程对资源的请求&lt;/strong&gt;，从而使得死锁的必要条件在系统执行的任何时间上都不满足&lt;/p&gt;
&lt;p&gt;破坏死锁产生的四个必要条件的其中之一，主要是&lt;strong&gt;破坏占有并等待，和循环等待&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1、静态分配策略&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;是指一个进程必须在执行前就申请到它所需要的全部资源，并且知道它所要的资源都得到满足之后才开始执行。缺点：降低资源的利用率，有些资源后续才使用，可能导致一个进程占用了一些几乎不用的资源而使得其他需要该资源的进程产生等待。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2、层次分配策略&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;将资源分为多个层次，一个进程得到某一层的一个资源后，只能再申请较高一层的资源。释放的时候，需要先释放高层资源。这样就不会出现循环等待、&lt;/p&gt;
&lt;h3 id=&#34;2避免&#34;&gt;&lt;strong&gt;2.避免&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;则是系统在分配资源时，根据资源的使用情况&lt;strong&gt;提前做出预测&lt;/strong&gt;，从而&lt;strong&gt;避免死锁的发生&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;允许四个条件出现，但是根据系统状态（安全和不安全）在分配资源的时候判断是否安全，安全才可以分配。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;银行家算法：在分配资源前，&lt;strong&gt;会检查是否&lt;/strong&gt;存在一个安全序列，能够&lt;/strong&gt;依次满足&lt;strong&gt;所有进程完成。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;3检测&#34;&gt;&lt;strong&gt;3.检测&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;是指系统设有&lt;strong&gt;专门的机构&lt;/strong&gt;，当死锁发生时，该机构能够检测死锁的发生，并精确地确定与死锁有关的进程和资源。类似乐观锁的思想，等发生了再去解决。可利用&lt;strong&gt;进程-资源分配图&lt;/strong&gt;检测系统是否处于死锁。&lt;/p&gt;
&lt;p&gt;用一个方框表示每一个资源类，方框中的黑点表示该资源类中的各个资源，用一个圆圈表示每一个进程，用 &lt;strong&gt;有向边&lt;/strong&gt; 来表示&lt;strong&gt;进程申请资源和资源被分配的情况&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;死锁检测算法是通过&lt;strong&gt;检测有向图是否存在环来实现&lt;/strong&gt;，从一个节点出发进&lt;strong&gt;行深度优先搜索&lt;/strong&gt;，&lt;strong&gt;对访问过的节点进行标记，如果访问了已经标记的节点&lt;/strong&gt;，就表示有向图存在环，也就是检测到死锁的发生。&lt;/p&gt;
&lt;h3 id=&#34;4解除&#34;&gt;&lt;strong&gt;4.解除&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;是与检测相配套的一种措施，用于&lt;strong&gt;将进程从死锁状态下解脱出来&lt;/strong&gt;。、&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;立即结束所有进程的执行&lt;/strong&gt;，重新启动操作系统 ：这种方法简单，但以前所在的工作全部作废，损失很大。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;撤销涉及死锁的所有进程&lt;/strong&gt;，&lt;strong&gt;解除死锁后继续运行&lt;/strong&gt;：这种方法能彻底打破死锁的循环等待条件，但将付出很大代价，例如有些进程可能已经计算了很长时间，由于被撤销而使产生的部分结果也被消除了，再重新执行时还要再次进行计算。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;逐个撤销涉及死锁的进程&lt;/strong&gt;，回收其资源直至死锁解除。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;抢占资源&lt;/strong&gt;：从涉及死锁的一个或几个进程中抢占资源，把夺得的资源再分配给涉及死锁的进程直至死锁解除&lt;/p&gt;
&lt;h1 id=&#34;内存管理&#34;&gt;内存管理
&lt;/h1&gt;&lt;p&gt;负责内存的分配与回收&lt;/p&gt;
&lt;p&gt;地址转换：将虚拟地址转换为内存中的物理地址&lt;/p&gt;
&lt;p&gt;内存扩充：没有足够的内存时，利用虚拟内存技术&lt;/p&gt;
&lt;h2 id=&#34;内存碎片&#34;&gt;内存碎片
&lt;/h2&gt;&lt;p&gt;在内存的申请和释放过程中产生的，通常分为下面两种&lt;/p&gt;
&lt;p&gt;**内部内存碎片(Internal Memory Fragmentation，简称为内存碎片)：已经分配给进程使用但是未被使用的内存。**产生原因是分配的时候采用固定比例，分配的内存大于需要的空间。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;外部内存碎片(External Memory Fragmentation，简称为外部碎片)&lt;/strong&gt;：内存中较小的内存块，无法满足一个进程的需求&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/image%201.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;/img/image.png&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;内存管理方式&#34;&gt;内存管理方式
&lt;/h2&gt;&lt;h3 id=&#34;1连续内存管理&#34;&gt;1.连续内存管理
&lt;/h3&gt;&lt;p&gt;为一个用户程序分配一个连续的内存空间&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;块式管理&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;将内存按固定块划分&lt;/strong&gt;，每个块中只包含一个进程。如果程序运行需要内存的话，操作系统就分配给它一块。linux中为了解决外部碎片问题，采用伙伴系统算法实现，思想是内存按照2的幂次方分配，将相邻的内存组成一对伙伴。当进行内存分配时，伙伴系统会尝试找到大小最合适的内存块。如果找到的内存块过大，就将其一分为二，分成两个大小相等的伙伴块。如果还是大的话，就继续切分，直到到达合适的大小为止。假设两块相邻的内存块都被释放，系统会将这两个内存块合并，进而形成一个更大的内存块&lt;/p&gt;
&lt;p&gt;缺点：容易造成内部碎片。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;固定分区分配&lt;/strong&gt;（使用分区使用表）
分区大小相等（缺乏灵活性，造成内存空间浪费）
分区大小不等&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;动态分区分配/可变分区分配&lt;/strong&gt;（数据结构：空闲分区表或空闲分区链）
存储保护：重定位寄存器（基址寄存器和限长寄存器）：对内存的访问进行保护
基址寄存器：记录进程在内存中的起始物理地址
限长寄存器：记录进程逻辑地址长度
&lt;strong&gt;动态分区分配算法&lt;/strong&gt;
&lt;strong&gt;首次适应（First Fit）&lt;/strong&gt;：从头开始找到的第一个足够大的分区（执行最快）。对空闲表项地址从大到小排列。
&lt;strong&gt;循环首次适应（Next Fit）&lt;/strong&gt;：首次适应的变种，从上次找到的位置继续往下找，找到的第一个足够大的分区
&lt;strong&gt;最佳适应（Best Fit）&lt;/strong&gt;：搜索所有可用分区，找到的足够大但却最小的分区.要求所有空闲分区按其容量从小到大顺序形成空闲分区链。这样找到的第一个就满足。（很多碎片）
&lt;strong&gt;最差适应（Worst Fit&lt;/strong&gt;）：搜索所有可用分区，找到的最大的分区。（减少碎片）
&lt;strong&gt;回收内存&lt;/strong&gt;
（1）前面有空闲区，则合并，不必为回收分区分配新表项，只需修改前面分区的大小
（2）后面有空闲区，则合并，使用回收区首址作为新空闲区首址
（3）前面后面都有空闲区，则合并，使用前面的表项和首址，取消后面的表项
（4）前面后面都没有空闲区，则合并，为回收分区分配新表项碎片&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;2非连续内存管理&#34;&gt;2.非连续内存管理
&lt;/h3&gt;&lt;p&gt;允许一个程序使用内存分布在不相邻的内存中。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;段式管理&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;以段(一段连续的物理内存)的形式管理/分配物理内存。段是有实际意义的，每个段定义了一组逻辑信息，例如,有主程序段MAIN、子程序段 X、数据段 D 及栈段 S 等。 段式管理通过&lt;strong&gt;段表&lt;/strong&gt;对应&lt;strong&gt;逻辑地址和物理地址。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;缺点：导致内存外部碎片。 因为段和段之间容易留下空间无法使用&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;页式管理&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;把内存分为大小相等且固定的一页一页的形式&lt;/strong&gt;，页较小，相对相比于&lt;strong&gt;块式管理的划分力度更大&lt;/strong&gt;，提高了内存利用率，减少了碎片。任意的虚拟页可以被映射到物理内存呢中的任意物理页上&lt;/p&gt;
&lt;p&gt;逻辑地址=页号+业内地址  物理地址=快号+业内地址&lt;/p&gt;
&lt;p&gt;没有外碎片，有内碎片&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;段页式管理&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;页是物理单位，段是逻辑单位。分页可以有效提高内存利用率，分段可以更好满足用户需求&lt;/p&gt;
&lt;p&gt;段页式管理：把内存分成若干段，每个段分成若个页&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;分页机制和分段机制有哪些共同点和区别呢？&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;共同点 ：&lt;/p&gt;
&lt;p&gt;分页机制和分段机制都是为了提高内存利用率，减少内碎片。&lt;/p&gt;
&lt;p&gt;页和段都是&lt;strong&gt;离散存储&lt;/strong&gt;的，属于非连续存储管理。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;区别 ：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;页是物理单位&lt;/strong&gt;，即操作系统&lt;strong&gt;将物理内存划分成固定大小的页面&lt;/strong&gt;，每个页面的大小通常是 2 的幂次方。段则是逻辑单位，是为了满足&lt;strong&gt;程序&lt;/strong&gt;对内存空间的逻辑需求而设计的，根据程序中的数据和代码的逻辑结构来划分。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;页的大小是固定的&lt;/strong&gt;，由操作系统决定；而&lt;strong&gt;段的大小不固定&lt;/strong&gt;，取决于我们当前运行的程序。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;分段机制容易出现外部内存碎片，分页机制解决了外部内存碎片问题&lt;/strong&gt;，但是仍然可能出现内部内存碎片。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;虚拟内存&#34;&gt;虚拟内存
&lt;/h1&gt;&lt;p&gt;虚拟内存是指逻辑上存在，是假象的，主要作用是为进程访问主存（物理内存）的桥梁并简化内存管理&lt;/p&gt;
&lt;h3 id=&#34;优点为什么要用&#34;&gt;优点（为什么要用）
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;隔离进程。每个进程都有对应的虚拟地址空间，进程之间彼此隔离&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;提升物理内存利用率。操作系统只需要将当前进程正在使用的部分数据载入物理内存&lt;/li&gt;
&lt;li&gt;简化内存管理。不用和真正物理内存打交道，而是借组虚拟地址空间访问&lt;/li&gt;
&lt;li&gt;实现多个进程共享物理内存。&lt;/li&gt;
&lt;li&gt;提高内存使用的安全性：控制进程对物理内存的访问，避免造成系统崩溃&lt;/li&gt;
&lt;li&gt;提供更大的可使用内存空间：物理内存不够的时候，可以利用磁盘充当。将物理内存页保存到磁盘，就是读写速度会慢一点。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;逻辑虚拟地址和物理地址&#34;&gt;&lt;strong&gt;逻辑(虚拟)地址和物理地址&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;物理地址指真实物理内存的中的地址，也就是&lt;strong&gt;内存地址寄存器&lt;/strong&gt;的地址。物理地址的集合叫物理地址空间。&lt;/p&gt;
&lt;p&gt;逻辑地址：比如说在程序中某个对象在堆上的地址。虚拟内存地址的集合叫虚拟地址空间。逻辑地址包括&lt;strong&gt;段基地址&lt;/strong&gt;（在内存中的起始位置）和&lt;strong&gt;偏移地址&lt;/strong&gt;（距离段基地址的偏移量）
为什么需要有两个地址？&lt;strong&gt;逻辑地址可以让地址分配更加灵活，比如逻辑地址中连续的地址可以在物理地址中不连续。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;将虚拟地址翻译成物理地址的主要机制有：&lt;strong&gt;分段机制和分页机制和段页机制&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;分段机制&#34;&gt;分段机制
&lt;/h3&gt;&lt;p&gt;通过&lt;strong&gt;段表&lt;/strong&gt;映射虚拟地址和物理地址&lt;/p&gt;
&lt;p&gt;虚拟地址由两部分组成：&lt;strong&gt;段号，段内偏移量&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;具体地址翻译过程如下：首先解析得到虚拟地址的段号，然后在段表中根据段号找到该段的起始地址。该段的起始地址加上段内偏移量得到最终的物理地址。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/image%202.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image.png&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;段表中还有段长（检查虚拟地址是否超出合法范围），段类型等信息&lt;/p&gt;
&lt;p&gt;通过段号不一定可以找到对应的段表项目。&lt;/p&gt;
&lt;h3 id=&#34;分页机制&#34;&gt;分页机制
&lt;/h3&gt;&lt;p&gt;通过&lt;strong&gt;页表&lt;/strong&gt;映射。&lt;/p&gt;
&lt;p&gt;虚拟地址由两部分组成：&lt;strong&gt;页号，页内偏移量。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;具体地址翻译过程如下：首先解析得到虚拟地址的页号号，然后在页表中根据页号找到该页的起始地址。该页的起始地址加上页内偏移量得到最终的物理地址。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/image%203.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image.png&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;页表中号存储如访问标志（标志该页面有没有被访问过）等信息&lt;/p&gt;
&lt;h3 id=&#34;多级页表&#34;&gt;&lt;strong&gt;多级页表&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;为了避免把全部页表一直放在内存中占用过多空间，可以压缩页表占用的内存。&lt;/p&gt;
&lt;p&gt;比如说二级页表，一级页表项可以覆盖更大的范围，然后一个页表项再对应二级页表项。那么如果某一个一级页表项用不到，就不创建它对应的二级页表项。&lt;/p&gt;
&lt;p&gt;多级页表属于时间换空间，增加页表查询的次数减少页表的占用空间&lt;/p&gt;
&lt;h3 id=&#34;块表&#34;&gt;块表
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;为了解决虚拟地址到物理地址的转换速度，&lt;strong&gt;操作系统在 页表方案 基础之上引入了 快表
可以理解为一种特殊的&lt;/strong&gt;高速缓冲存储器&lt;/strong&gt;（Cache），缓存了虚拟页号到物理页号的映射关系。&lt;/p&gt;
&lt;p&gt;使用快表之后的地址转换流程是这样的：
根据虚拟地址中的页号查&lt;strong&gt;快表&lt;/strong&gt;；
如果该页在快表中，直接从快表中读取相&lt;strong&gt;应的物理地址&lt;/strong&gt;；
如果该页不在快表中，就访问&lt;strong&gt;内存中的页表&lt;/strong&gt;，再从页表中得到物理地址，同时将&lt;strong&gt;页表中的该映射表项添加到快表中；&lt;/strong&gt;
当快表填满后，又要登记新页时，就按照一定的淘汰策略淘汰掉快表中的一个页。&lt;/p&gt;
&lt;p&gt;由于页表也在主存中，因此在没有块表的时候，需要访问两次主存。&lt;/p&gt;
&lt;h3 id=&#34;页缺失&#34;&gt;页缺失
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;硬性页缺失（Hard Page Fault）&lt;/strong&gt;：物理内存中没有对应的物理页。会从磁盘文件中加载相应的内容到物理内存中。
&lt;strong&gt;软性页缺失（Soft Page Fault）&lt;/strong&gt;：物理内存中有对应的物理页，但虚拟页还未和物理页建立映射。&lt;/p&gt;
&lt;h3 id=&#34;页面置换算法&#34;&gt;页面置换算法
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;最佳页面置换算法（OPT，Optimal）&lt;/strong&gt;：优先选择淘汰的页面是**以后永不使用的，&lt;strong&gt;或者是&lt;/strong&gt;在最长时间内不再被访问的页面，**这样可以保证获得最低的缺页率。但由于人们目前无法预知进程在内存下的若干页面中哪个是未来最长时间内不再被访问的，因而该算法无法实现，只是理论最优的页面置换算法，可以作为衡量其他置换算法优劣的标准。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;先进先出页面置换算法（FIFO，First In First Out）&lt;/strong&gt; : 最简单的一种页面置换算法，总是&lt;strong&gt;淘汰最先进入内存的页面&lt;/strong&gt;，即选择在内存中驻留时间最久的页面进行淘汰。（&lt;strong&gt;经常访问或者需要长期存在的页面会被频繁调入调出）&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;最近最久未使用页面置换算法（LRU ，Least Recently Used）&lt;/strong&gt;：LRU 算法赋予每个页面一个访问字段，用来记录一个页面自上次被访问以来所经历的时间 T，当须淘汰一个页面时，选择现有页面中其 T 值最大的，即最近最久未使用的页面予以淘汰。（使用最多）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;最少使用页面置换算法（LFU，Least Frequently Used）&lt;/strong&gt; : 和 LRU 算法比较像，不过该置换算法选择的&lt;strong&gt;是之前一段时间内使用最少的页面&lt;/strong&gt;作为淘汰页。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;时钟页面置换算法（Clock）&lt;/strong&gt;：可以认为是一种最近未使用算法，即逐出的页面都是最近没有使用的那个。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;局部性原理&#34;&gt;局部性原理
&lt;/h3&gt;&lt;p&gt;局部性原理是指在程序执行过程中，数据和指令的访问存在一定的空间和时间上的局部性特点。其中，时间局部性是指一个数据项或指令在&lt;strong&gt;一段时间内被反复使用&lt;/strong&gt;的特点，空间局部性是指一个数据项或指令在一段时间内&lt;strong&gt;与其相邻的数据项或指令被反复&lt;/strong&gt;使用的特点。&lt;/p&gt;
&lt;p&gt;在分页机制中，页表的作用是将虚拟地址转换为物理地址，从而完成内存访问。在这个过程中，局部性原理的作用体现在两个方面：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;时间局部性&lt;/strong&gt;：由于程序中&lt;strong&gt;存在一定的循环或者重复操作&lt;/strong&gt;，因此会&lt;strong&gt;反复访问同一个页或一些特定&lt;/strong&gt;的页，这就体现了时间局部性的特点。为了利用&lt;strong&gt;时间局部性&lt;/strong&gt;，分页机制中通常采&lt;strong&gt;用缓存机制来&lt;/strong&gt;提高页面的命中率，即将&lt;strong&gt;最近访问过的&lt;/strong&gt;一些页放入缓存中，如果下一次访问的页已经在缓存中，就不需要再次访问内存，而是直接从缓存中读取。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;空间局部性&lt;/strong&gt;：由于程序中数据和指令的访问通常是具有一定的空间连续性的，因此&lt;strong&gt;当访问某个页时，往往会顺带访问其相邻的一些页&lt;/strong&gt;。为了利用空间局部性，分页机制中通常采用预取技术来&lt;strong&gt;预先将相邻的一些页读入内存缓存中&lt;/strong&gt;，以便在未来访问时能够直接使用，从而提高访问速度。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;文件系统&#34;&gt;文件系统
&lt;/h1&gt;&lt;p&gt;主要负责管理和组织计算机存储设备上的文件和目录，&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;存储管理&lt;/strong&gt;：将文件数据存储到物理存储介质中，并且管理空间分配，以确保每个文件都有足够的空间存储，并避免文件之间发生冲突。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;文件管理&lt;/strong&gt;：文件的创建、删除、移动、重命名、压缩、加密、共享等等。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;目录管理&lt;/strong&gt;：目录的创建、删除、移动、重命名等等。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;文件访问控制&lt;/strong&gt;：管理不同用户或进程对文件的访问权限，以确保用户只能访问其被授权访问的文件，以保证文件的安全性和保密性&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;硬链接和软链接的区别&#34;&gt;硬链接和软链接的区别
&lt;/h2&gt;&lt;h2 id=&#34;硬链接为什么不能跨文件系统&#34;&gt;&lt;strong&gt;硬链接为什么不能跨文件系统？&lt;/strong&gt;
&lt;/h2&gt;&lt;h2 id=&#34;提高文件系统性能的方式&#34;&gt;提高文件系统性能的方式
&lt;/h2&gt;&lt;h2 id=&#34;常见的磁盘调度算法&#34;&gt;常见的磁盘调度算法
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;先来先服务&lt;/p&gt;
&lt;p&gt;按照磁盘请求的顺序进行调度。简单公平，平均寻道时间较长&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;最短寻道时间优先&lt;/p&gt;
&lt;p&gt;优先调度与当前磁头所在磁道距离最近的磁道。
虽然平均寻道时间比较低，但是不够公平。如果新到达的磁道请求总是比一个在等待的磁道请求近，那么在等待的磁道请求会一直等待下去，也就是出现饥饿现象。具体来说，两端的磁道请求更容易出现饥饿现象。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;将数据从缓冲区读出写入磁盘这之间经历了几次复制&#34;&gt;&lt;strong&gt;将数据从缓冲区读出写入磁盘，这之间经历了几次复制&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/image%204.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image.png&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;第一次拷贝，把磁盘上的数据拷贝到操作系统内核的缓冲区里，这个拷贝的过程是通过 DMA 搬运的。
第二次拷贝，把内核缓冲区的数据拷贝到用户的缓冲区里，于是我们应用程序就可以使用这部分数据了，这个拷贝到过程是由 CPU 完成的。
第三次拷贝，把刚才拷贝到用户的缓冲区里的数据，再拷贝到内核的 socket 的缓冲区里，这个过程依然还是由 CPU 搬运的。
第四次拷贝，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程又是由 DMA 搬运的。&lt;/p&gt;
&lt;p&gt;会经历4次上下文切换，2次CPU拷贝，2次DMA拷贝
上下文切换：当用户程序向内核发起系统调用时，CPU 将用户进程从用户态切换到内核态；当系统调用返回时，CPU 将用户进程从内核态切换回用户态。
CPU拷贝：由 CPU 直接处理数据的传送，数据拷贝时会一直占用 CPU 的资源。
DMA拷贝：由 CPU 向DMA磁盘控制器下达指令，让 DMA 控制器来处理数据的传送，数据传送完毕再把信息反馈给 CPU，从而减轻了 CPU 资源的占有率。&lt;/p&gt;
&lt;p&gt;但是有时候用户并不会对数据进行加工，所以没必要将数据拷贝到用户缓冲区。也就有一种新技术：零拷贝&lt;/p&gt;
&lt;p&gt;零拷贝的实现：（优化技术）
①mmap+write&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/image%205.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image.png&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;具体过程如下:
1.应用进程调用了 mmap()后，DMA 会把磁盘的数据拷贝到内核的缓冲区里。接着，应用进程跟操作系统内核「共
享」这个缓冲区;
2.应用进程再调用 write()，操作系统直接将内核缓冲区的数据拷贝到 socket 缓冲区中，这一切都发生在内核态，由
CPU 来搬运数据;
3.最后，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程是由 DMA 搬运的。
我们可以得知，通过使用 mmap() 来代替 read()， 可以减少一次数据拷贝的过程。&lt;/p&gt;
&lt;h1 id=&#34;linux&#34;&gt;Linux
&lt;/h1&gt;&lt;h2 id=&#34;linux文件系统&#34;&gt;Linux文件系统
&lt;/h2&gt;&lt;p&gt;一切被操作系统管理的资源都被视为文件。这种设计使得 Linux 系统可以通过统一的文件接口来管理和操作不同类型的资源，从而实现了一种统一的文件操作方式。&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
